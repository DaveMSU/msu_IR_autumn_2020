{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip # Для работы архиватора.\n",
    "from tqdm.notebook import tqdm\n",
    "from math import trunc              # Для корректной работы функции бинарного поиска.\n",
    "from collections import defaultdict # Для построения словаря обратного индекса.\n",
    "import random                       # Для формирования id для узлов в дереве.\n",
    "from copy import deepcopy           # В тех местах, где передаются списки, нужно\n",
    "                                    #  передавать их копии, чтобы не изменять оригинал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data(dirname):\n",
    "    \n",
    "    # Для того, чтобы почистить url от сиволов типа \\x*\n",
    "    #\n",
    "    def __cleaned(dirty_url):\n",
    "    \n",
    "        ord_th = 46\n",
    "\n",
    "        buf = \"\"\n",
    "\n",
    "        for c in dirty_url:\n",
    "\n",
    "            buf += c\n",
    "\n",
    "            if len(buf) == 4:\n",
    "                if buf != \"http\":\n",
    "                    buf = buf[1:]      \n",
    "\n",
    "            if (ord(buf[-1]) < ord_th) and ('http' in buf):\n",
    "                    return buf[:-1]\n",
    "        return buf[:-1]\n",
    "\n",
    "    \n",
    "    # Получаем из всех не предобработанных\n",
    "    # файлов список из слов.\n",
    "    #\n",
    "    data = []\n",
    "    for i in range(1,8+1,1):\n",
    "\n",
    "        filename = \"file_\" + str(i) + \".gz\"\n",
    "        with gzip.open(dirname + filename) as f:\n",
    "            data.extend(f.read().decode(\"utf-8\", errors=\"ignore\").lower().split())\n",
    "            \n",
    "    # Формируем словарь вида - {url: list of word}\n",
    "    # И множество (set) всех слов в корпусе.\n",
    "    #\n",
    "    buffer = []\n",
    "    cites  = dict()\n",
    "    word_set = set(data)\n",
    "\n",
    "    for word in data:\n",
    "\n",
    "        if 'http' in word:\n",
    "            if len(buffer) > 2:\n",
    "                cites[__cleaned(buffer[0])] = buffer[1:]\n",
    "                word_set.remove(buffer[0])\n",
    "            buffer = []\n",
    "        buffer.append(word)\n",
    "            \n",
    "    return cites, word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.22 s, sys: 332 ms, total: 6.55 s\n",
      "Wall time: 6.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Main:\n",
    "#\n",
    "cites, word_set = clear_data('dataset/')                      # Словарь вида {url сайта: список слов на сайте}\n",
    "term_to_id = {word: i for i, word in enumerate(word_set)}     # -//- {слово: id слова} (нумерация с 0 до ~300k)\n",
    "url_to_docid = {url: i for i, url in enumerate(cites.keys())} # -//- {url: id сайта} (нумерация с 0 до ~9k)\n",
    "docid_to_url = {i: url for i, url in enumerate(cites.keys())} # -//- {id сайта: url}\n",
    "\n",
    "\n",
    "reversed_index = defaultdict(list)                            # Словарь обратных индексов вида\n",
    "for i, (url, word_list) in enumerate(cites.items()):          #  {id слова: все id сайтов, на которых оно есть}\n",
    "    for word in word_list:\n",
    "        reversed_index[term_to_id[word]].append(url_to_docid[url]) # Already sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple9_encoder_decoder():\n",
    "    def __init__(self):\n",
    "\n",
    "        # Формируем маски-константы.\n",
    "        #\n",
    "        code_9 = 0x90000000 # 1001 0000 0000 ... 0000\n",
    "        code_8 = 0x80000000 # 1000 0000 0000 ... 0000\n",
    "        code_7 = 0x70000000 # 0111 0000 0000 ... 0000\n",
    "        code_6 = 0x60000000 # 0110 0000 0000 ... 0000\n",
    "        code_5 = 0x50000000 # 0101 0000 0000 ... 0000\n",
    "        code_4 = 0x40000000 # 0100 0000 0000 ... 0000\n",
    "        code_3 = 0x30000000 # 0011 0000 0000 ... 0000\n",
    "        code_2 = 0x20000000 # 0010 0000 0000 ... 0000\n",
    "        code_1 = 0x10000000 # 0001 0000 0000 ... 0000\n",
    "        \n",
    "        self.encode_type = [[28, 2**1  - 1, code_9,  1],     \n",
    "                            [14, 2**2  - 1, code_8,  2],\n",
    "                            [ 9, 2**3  - 1, code_7,  3],\n",
    "                            [ 7, 2**4  - 1, code_6,  4],\n",
    "                            [ 5, 2**5  - 1, code_5,  5],\n",
    "                            [ 4, 2**7  - 1, code_4,  7],\n",
    "                            [ 3, 2**9  - 1, code_3,  9],\n",
    "                            [ 2, 2**14 - 1, code_2, 14],\n",
    "                            [ 1, 2**28 - 1, code_1, 28]\n",
    "                           ]\n",
    "\n",
    "        self.decode_type = {code_9: [28, 2**1  - 1,  1],     \n",
    "                            code_8: [14, 2**2  - 1,  2],\n",
    "                            code_7: [9,  2**3  - 1,  3],\n",
    "                            code_6: [7,  2**4  - 1,  4],\n",
    "                            code_5: [5,  2**5  - 1,  5],\n",
    "                            code_4: [4,  2**7  - 1,  7],\n",
    "                            code_3: [3,  2**9  - 1,  9],\n",
    "                            code_2: [2,  2**14 - 1, 14],\n",
    "                            code_1: [1,  2**28 - 1, 28]\n",
    "                           }\n",
    "        \n",
    "    def encode(self, a):\n",
    "        \"\"\"\n",
    "        Метод класса, позволяюзий КОДИРОВАТЬ\n",
    "        список элементов a, по принципу Simple9.\n",
    "        \"\"\"\n",
    "\n",
    "        offset    = 0        \n",
    "        res       = []\n",
    "        list_size = len(a)\n",
    "\n",
    "        while offset < list_size:        \n",
    "\n",
    "            for current_encode_type in self.encode_type:\n",
    "\n",
    "                n     = current_encode_type[0] # Кол-во чисел которые могут поместиться на регистр.\n",
    "                th    = current_encode_type[1] # Верхнее возможное число для выбранного code_x.\n",
    "                code  = current_encode_type[2] # Запоминаем n (важны лишь первые 4 бита)\n",
    "                shift = current_encode_type[3] # На сколько сдвигать указатель при обработке.\n",
    "                 \n",
    "                # В идеале менять порядок следования элементов и их запоминать,\n",
    "                #  но мы обойдемся тем, что будем обрезать по максимальному.\n",
    "                #\n",
    "                last_n_max = max(a[offset:offset + n])\n",
    "\n",
    "                if (offset + n <= list_size) and (last_n_max <= th):\n",
    "\n",
    "                    tmp = a[offset]\n",
    "                    for i in range(1, n): \n",
    "                        tmp |= (a[offset + i] << (shift * i))\n",
    "\n",
    "                    res.append(tmp | code)\n",
    "                    offset += n\n",
    "                    break\n",
    "\n",
    "        return res\n",
    "    \n",
    "\n",
    "    def decode(self, a):\n",
    "        \"\"\"\n",
    "        Метод класса, позволяюзий ДЕКОДИРОВАТЬ\n",
    "        список элементов a, по принципу Simple9.\n",
    "        \"\"\"        \n",
    "        \n",
    "        res = []\n",
    "        for cur_num in a:\n",
    "\n",
    "            code = cur_num & 0xf0000000 # cur_num & (1111 0000 0000 ... 0000) - маска для типа SimpleX.\n",
    "            data = cur_num & 0x0fffffff # cur_num & (0000 1111 1111 ... 1111) - маска для элементов.\n",
    "            info = self.decode_type[code]\n",
    "\n",
    "            n     = info[0] # Кол-во чисел которые могут поместиться на регистр.\n",
    "            bit   = info[1] # Соответствующая бинарная последовательность 1-иц.\n",
    "            shift = info[2] # На сколько сдвигать указатель при обработке.\n",
    "\n",
    "            for i in range(n):\n",
    "                res.append(data & bit)            \n",
    "                data >>= shift\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main:\n",
    "#\n",
    "all_data = []\n",
    "for key, lizt in reversed_index.items():\n",
    "    \n",
    "    # Меняем структуру хранения обратных индексов из словаря в список - просто последовательность чисел.\n",
    "    # Запись идет в следующем формате:\n",
    "    #  docid  ->  N (lenght of list)  ->  0-st elem in list  ->  1-st of dif_list  ->  ...  ->  N-st of dif_list  ->  docid  ->  ...\n",
    "    #  (dif_list = differentiated list)\n",
    "    #\n",
    "    tmp_list = deepcopy(lizt)\n",
    "    for i in range(len(tmp_list)-1, 0, -1):\n",
    "        tmp_list[i] = tmp_list[i] - tmp_list[i-1]\n",
    "    batch = [key] + [len(tmp_list)] + tmp_list\n",
    "    all_data.extend(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 136 ms, total: 12.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main:\n",
    "#\n",
    "compresser = Simple9_encoder_decoder()        # Создаем объект класса Simple9.\n",
    "compressed_data = compresser.encode(all_data) # Сжимаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... передача сжатых данных по сети ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 s, sys: 123 ms, total: 1.97 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uncompressed_data = compresser.decode(compressed_data) # Декодируем данные обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 837 ms, sys: 0 ns, total: 837 ms\n",
      "Wall time: 842 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "assert(len(all_data) == len(uncompressed_data)) # Проверяем, что все корректно отработало.\n",
    "\n",
    "for i in range(len(all_data)):\n",
    "    assert(all_data[i] == uncompressed_data[i]) # Проверяем, что все корректно отработало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.31 s, sys: 124 ms, total: 7.44 s\n",
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parse_state  = 0\n",
    "new_reversed_index = defaultdict(list)\n",
    "\n",
    "for elem in uncompressed_data: # Формируем словарь обратных индексов по данной последовательности чисел.\n",
    "    \n",
    "    if   parse_state == 0: # Когда текущий elem - termid.\n",
    "        key = elem\n",
    "        parse_state = 1\n",
    "    \n",
    "    elif parse_state == 1: # Когда текущий elem - lenght of the next list.\n",
    "        list_len = elem        \n",
    "        current_list = []\n",
    "        parse_state = 2\n",
    "        \n",
    "    elif parse_state == 2: # Когда текущий elem - list of docid.\n",
    "        list_len -= 1\n",
    "        if len(current_list):\n",
    "            current_list.append(elem + current_list[-1])        \n",
    "        else:\n",
    "            current_list.append(elem)\n",
    "        if list_len == 0:\n",
    "            parse_state = 0            \n",
    "            new_reversed_index[key] = deepcopy(current_list)            \n",
    "    \n",
    "    else:\n",
    "        raise \"error7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(reversed_index) == len(new_reversed_index)) # Проверяем, что все корректно отработало.\n",
    "\n",
    "for i in range(len(reversed_index)):    \n",
    "    assert(reversed_index[i] == new_reversed_index[i]) # Проверяем, что все корректно отработало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все проверки прошли, удалим старый список, чтобы далее фигурировало название получше.\n",
    "#\n",
    "reversed_index = new_reversed_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    \"\"\"\n",
    "    Основная функция.\n",
    "    \n",
    "    input: запрос заданный в виде бульевого запроса\n",
    "    \n",
    "    output: список сайтов, удовлетворяющих ему.\n",
    "    \"\"\"\n",
    "    \n",
    "    global docid_to_url # Чтобы в конце по docid получить url'ы.\n",
    "\n",
    "    def get_formula(query):    \n",
    "        \"\"\"\n",
    "        Вспомогательная функция.\n",
    "        \n",
    "        input: строка - запрос в формате бульевого запроса.\n",
    "        \n",
    "        output: список строк - где каждый объект\n",
    "         либо операция,\n",
    "         либо операнд,\n",
    "         либо скобка\n",
    "         в бульевом запросе.\n",
    "        \"\"\"\n",
    "\n",
    "        lizt, buf = [], \"\"\n",
    "\n",
    "        for c in query.lower():\n",
    "\n",
    "            if not c.isalpha():\n",
    "\n",
    "                if buf.strip():\n",
    "                    lizt.append(buf)\n",
    "\n",
    "                if c.strip():\n",
    "                    lizt.append(c)\n",
    "                buf = \"\"\n",
    "\n",
    "            else:    \n",
    "                buf += c\n",
    "        if buf.strip():\n",
    "            lizt.append(buf)  \n",
    "\n",
    "        return lizt    \n",
    "\n",
    "    \n",
    "    def get_polish_notation(formula):\n",
    "        \"\"\"\n",
    "        Вспомогательная функция.\n",
    "        \n",
    "        Input: список строк - выход функции get_formula(query) (инфексная запись формулы)\n",
    "        \n",
    "        Output: список строк - та же формула, но в порядке обратной польской записи.\n",
    "        \"\"\"\n",
    "\n",
    "        prior = {'!': 3, '&': 2, '|': 1, '(': 0}\n",
    "        polskRecord = []\n",
    "        stack = []\n",
    "\n",
    "        def condition(stack, elem):\n",
    "\n",
    "            if len(stack) > 0:\n",
    "                if prior[stack[-1]] >= prior[elem]:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "\n",
    "        for elem in formula:\n",
    "\n",
    "            if elem == '(':\n",
    "                stack.append(elem)\n",
    "\n",
    "            elif elem == ')':\n",
    "                while stack[-1] != '(':\n",
    "                    polskRecord.append(stack[-1])\n",
    "                    del stack[-1]\n",
    "                del stack[-1]\n",
    "\n",
    "            elif elem in prior.keys():\n",
    "                while condition(stack, elem):            \n",
    "                    polskRecord.append(stack[-1])\n",
    "                    del stack[-1]\n",
    "                stack.append(elem)\n",
    "\n",
    "            else:\n",
    "                polskRecord.append(elem)\n",
    "\n",
    "        polskRecord.extend(stack[::-1])\n",
    "\n",
    "        return polskRecord\n",
    "    \n",
    "\n",
    "\n",
    "    class getPtr:\n",
    "        \"\"\"\n",
    "        Класс функтор, который позволяет\n",
    "         получить указатель-адрес вершины дерева.\n",
    "        \"\"\"\n",
    "        def __init__(self):     \n",
    "            \"\"\"\n",
    "            Чтобы не было разных вершин с одним адресом.\n",
    "            \"\"\"\n",
    "            self.all_ptr = set()\n",
    "\n",
    "\n",
    "        def __call__(self):        \n",
    "            \"\"\"\n",
    "            При вывозове, возвращает \n",
    "             новый уникальный указатель.\n",
    "            \"\"\"\n",
    "            tmp = random.randint(0, 10000)\n",
    "\n",
    "            while tmp in self.all_ptr:\n",
    "                tmp = random.randint(0, 10000)\n",
    "            self.all_ptr.add(tmp)\n",
    "\n",
    "            return tmp\n",
    "        \n",
    "\n",
    "\n",
    "    get_ptr = getPtr()\n",
    "    binTree = dict()\n",
    "\n",
    "     \n",
    "    ###\n",
    "    \n",
    "    ##\n",
    "   \n",
    "    ##\n",
    "    \n",
    "    #\n",
    "    def find_intersection_by_streaming_passage(bin_tree, head_ptr, reversed_index, term_to_id):\n",
    "  \n",
    "        def bin_search(arr, key, l=0, r=-100):\n",
    "            \"\"\"\n",
    "            Функция бинарного поиска,\n",
    "             позволяет при потоковом обходе\n",
    "             быстрее находить следующий id в списке в листе,\n",
    "             ограниченный сверху docId.\n",
    "            \"\"\"\n",
    "\n",
    "            if r == -100:\n",
    "                r = len(arr) - 1\n",
    "\n",
    "            if l == len(arr) - 1:\n",
    "                return len(arr) - 1\n",
    "\n",
    "            if l > r:\n",
    "                return l\n",
    "\n",
    "            m = trunc((r + l) / 2)    \n",
    "\n",
    "            if   arr[m] > key:\n",
    "                return bin_search(arr, key, l,   m-1)\n",
    "\n",
    "            elif arr[m] < key:\n",
    "                return bin_search(arr, key, m+1, r)\n",
    "\n",
    "            else:\n",
    "                return m               \n",
    "\n",
    "        docId = -1 # Главный счётчик текущего инедкса.\n",
    "        res = []\n",
    "\n",
    "        def _run(cur_ptr, docId):\n",
    "            \"\"\"\n",
    "            Функция, позволяющая \n",
    "             произвоть потоковый проход\n",
    "             по дереву рекурсивно.\n",
    "            \"\"\"\n",
    "\n",
    "            cur_node = bin_tree[cur_ptr]\n",
    "\n",
    "            if cur_node[0] == 'BIN_OPERATION':\n",
    "                if   cur_node[1] == '&':\n",
    "                    return max(_run(cur_node[2], docId),\n",
    "                               _run(cur_node[3], docId))\n",
    "\n",
    "                elif cur_node[1] == '|':\n",
    "                    return min(_run(cur_node[2], docId),\n",
    "                               _run(cur_node[3], docId))\n",
    "\n",
    "                else:\n",
    "                    raise \"error1\"\n",
    "\n",
    "            elif cur_node[0] == 'UN_OPERATION':\n",
    "                if cur_node[1] == '!':\n",
    "                    tmp = _run(cur_node[2], docId)\n",
    "                    if tmp == docId:\n",
    "                        return tmp+1\n",
    "                    else:\n",
    "                        return docId\n",
    "                else:\n",
    "                    raise \"error3\"\n",
    "\n",
    "            elif cur_node[0] == 'OPERAND':\n",
    "                doc_list = reversed_index[cur_node[1]]\n",
    "\n",
    "                cur_node[2] = bin_search(doc_list, docId, l=cur_node[2])\n",
    "\n",
    "                if   cur_node[2] == len(doc_list)-1:\n",
    "                    return float(\"inf\")\n",
    "\n",
    "                elif doc_list[cur_node[2]] >= docId:\n",
    "                    return doc_list[cur_node[2]]\n",
    "\n",
    "                else:\n",
    "                    print(doc_list)\n",
    "                    print(cur_node)\n",
    "                    print(docId)\n",
    "                    raise \"error4\"\n",
    "\n",
    "            else:\n",
    "                raise \"error5\"                    \n",
    "\n",
    "\n",
    "        while docId < max_docId:\n",
    "\n",
    "            query_result = _run(head_ptr, docId)        \n",
    "            if docId == query_result:\n",
    "                res.append(docId)\n",
    "                docId += 1\n",
    "            else:\n",
    "                if docId < query_result:\n",
    "                    docId = query_result\n",
    "                else:\n",
    "                    raise \"error6\"\n",
    "\n",
    "        return res     \n",
    "            \n",
    "        \n",
    "        \n",
    "    def make_node(elem, stack, this_type):\n",
    "        \"\"\"\n",
    "        Вспомогательная функция, которая формирует дерево.\n",
    "        \"\"\"\n",
    "        ptr = get_ptr()\n",
    "\n",
    "        if this_type == 'OPERAND':\n",
    "            node = {ptr: ['OPERAND', elem, 0]}\n",
    "\n",
    "        elif this_type == 'UN_OPERATION':\n",
    "            node = {ptr: ['UN_OPERATION', elem, stack[-1]]}\n",
    "            del stack[-1]\n",
    "\n",
    "        elif this_type == 'BIN_OPERATION':\n",
    "            node = {ptr: ['BIN_OPERATION', elem, stack[-2], stack[-1]]}\n",
    "            del stack[-2:]\n",
    "\n",
    "        else:\n",
    "            raise \"error\"\n",
    "\n",
    "        stack.append(ptr)\n",
    "        binTree.update(node)\n",
    "\n",
    "        return stack \n",
    "    \n",
    "    # Основоне тело функции search:\n",
    "    \n",
    "    # Переводим запрос в список смысловых елементов (слова, скобки, символы &/|/!).\n",
    "    #\n",
    "    formula = get_formula(query) \n",
    "    \n",
    "    # Первеодим формулу в польскую запись.\n",
    "    #\n",
    "    polishRecord = get_polish_notation(formula)\n",
    "    \n",
    "    # Формализуем множество используемых символов-операций.\n",
    "    #\n",
    "    operations = {'&', '|', '!'}\n",
    "    stack = []\n",
    "\n",
    "    # Итерируемся по формуле, записанной в польской записи\n",
    "    #  и формируем дерево бинарного поиска.\n",
    "    #\n",
    "    for elem in polishRecord:\n",
    "\n",
    "        if elem in {'&', '|'}:\n",
    "            stack = make_node(elem, stack, 'BIN_OPERATION')\n",
    "        elif elem == '!':\n",
    "            stack = make_node(elem, stack, 'UN_OPERATION')        \n",
    "        else:\n",
    "            stack = make_node(term_to_id[elem], stack, 'OPERAND')\n",
    "            \n",
    "    # В стеке, находится корень.\n",
    "    #\n",
    "    head_ptr = stack[0]\n",
    "    \n",
    "    # Запоминаем максимульное значние индекса url'ов.\n",
    "    #\n",
    "    max_docId = max(url_to_docid.values())\n",
    "\n",
    "    # Получаем список из docid, сайтов удовлетворяющих запросу.\n",
    "    #\n",
    "    list_of_docid = find_intersection_by_streaming_passage(binTree, head_ptr, reversed_index, term_to_id)\n",
    "    \n",
    "    # По docid'шникам получаем сами url'ы.\n",
    "    #\n",
    "    needed_urls = []\n",
    "    for docid in list_of_docid:\n",
    "        needed_urls.append(docid_to_url[docid])\n",
    "        \n",
    "    return needed_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main:\n",
    "#\n",
    "query = \"власти & ( бельгии | парижа ) & ! теракт\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://lenta.ru/articles/2009/12/30/finalgermany/',\n",
       " 'http://lenta.ru/articles/2013/04/02/zapretnyplod/',\n",
       " 'http://lenta.ru/news/2006/07/05/paris',\n",
       " 'http://lenta.ru/news/2006/08/10/plot2/',\n",
       " 'http://lenta.ru/articles/2010/11/22/lebannon/',\n",
       " 'http://lenta.ru/news/2015/08/14/mts_vimpelkom_otkati/',\n",
       " 'http://lenta.ru/articles/2004/08/21/ruslan/']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main:\n",
    "#\n",
    "search(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
